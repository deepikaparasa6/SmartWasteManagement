{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPfUgyTl2h4JWqXCgXr+HhO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepikaparasa6/SmartWasteManagement/blob/develop/SmartWasteManagement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUEjZrawJCYq"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python tensorflow fastapi uvicorn streamlit kaggle matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload your kaggle.json API key\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d asdasdasasdas/garbage-classification\n",
        "!unzip garbage-classification.zip -d garbage_data\n"
      ],
      "metadata": {
        "id": "HPK4fxfaJOXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_dir = \"garbage_data/Garbage classification/Garbage classification\"\n",
        "print(\"Classes available:\", os.listdir(base_dir))\n"
      ],
      "metadata": {
        "id": "CR8tFG2JJPK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    base_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"Class names:\", class_names)\n"
      ],
      "metadata": {
        "id": "ph2G2lcDJPIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "image_path = f'{base_dir}/plastic/plastic1.jpg'\n",
        "img = cv2.imread(image_path)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img_rgb)\n",
        "plt.title(\"Plastic Waste Sample\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rkj64lQiJPGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(\n",
        "    buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "JTeyKpYYJPDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = os.listdir(base_dir)\n",
        "num_classes = len(classes)\n",
        "print(f\"We have {num_classes} classes\")\n",
        "total_images = 0\n",
        "for c in classes:\n",
        "    images = os.listdir(os.path.join(base_dir, c))\n",
        "    total_images += len(images)\n",
        "    print(f\"for category {c}, we have {len(images)} images\")\n",
        "\n",
        "print(f\"Total Images are: {total_images}\")"
      ],
      "metadata": {
        "id": "IiroLJ0HJPAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "base_model = MobileNetV2(input_shape=img_size + (3,),include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "base_model.trainable = False  # Freeze base model\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(6, activation='softmax')  # 6 classes\n",
        "])\n"
      ],
      "metadata": {
        "id": "UIz98ePsJO-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=25)\n"
      ],
      "metadata": {
        "id": "GYcnedM1JO5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('waste_classifier_model.h5')\n"
      ],
      "metadata": {
        "id": "2l3-4d_JJO2X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}